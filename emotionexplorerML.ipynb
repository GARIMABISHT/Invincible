import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline
from PIL import Image

# NN models
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import optimizers
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.models import load_model

from tqdm import tqdm
import glob
from sklearn.metrics import accuracy_score

# import warnings filter
from warnings import simplefilter
# ignore all future warnings
simplefilter(action='ignore', category=FutureWarning)
# Get path to data directory
import os
workingdir = os.path.abspath(os.getcwd())
datadir = workingdir + '\data'
expressiondir = datadir + "\\facial_expressions"'
expressiondir
datafile = expressiondir + '/data/legend.csv'
datafile2 = expressiondir + '/data/legend2.csv'
imagedir = expressiondir + '\\images'
IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL = 350, 350, 1
NUM_CLASSES = 3; 
facevalue = {'negative': 0, 'happiness': 1, 'neutral': 2}
emotionweights = {0:1, 1:1, 2:2}

def DecodeJPG(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.rgb_to_grayscale(img)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])

def ProcessFiles(data_id, im_filename, emotion):
    full_filename = imagedir + '\\' + im_filename
    img = tf.io.read_file(full_filename)
    img = DecodeJPG(img)
    return img, emotion
    file_labels = tf.data.experimental.CsvDataset(datafile, record_defaults=[tf.string, tf.string, tf.int32], header=True).shuffle(10000)
    img_labels = file_labels.map(ProcessFiles, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64).repeat()
img_labels_val = img_labels.take(2000) # validation
img_labels_tra = img_labels.skip(2000) # training
iterator = img_labels.make_initializable_iterator()
next_op = iterator.get_next()
with tf.Session() as sess:
    sess.run(iterator.initializer)
    sess.run(tf.tables_initializer())
    img, lab = sess.run(next_op)
    print(lab)
    img_list = glob.glob('data\MyFaces/*.png')
 tograyscale = True;

for img_file in img_list:
    img = Image.open(img_file)
    img = img.resize((IMG_WIDTH, IMG_HEIGHT))
    print('Original Image'); display(img); 
    
    if tograyscale:
        img = img.convert('L') #.convert('RGB')
        im = np.asarray(img)
    else:
        im = np.asarray(img)
        im = im[:,:,:3]
    im = im/255
    im_input = im.reshape((1,IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL))
    
    pred_class = model.predict_classes(im_input)[0]
    pred_class = list(facevalue.keys())[pred_class]
    label = model.predict(im_input)[0]
    
    plt.imshow(im); plt.axis('off');
    plt.show(); 

    print('This person is showing', list(facevalue.keys())[label.argmax()])
    plt.figure(figsize = (4,9))
    plt.imshow(label.reshape(1,3), vmax = 1, vmin= 0, cmap = 'Blues'); 
    plt.yticks([]); plt.xticks(np.arange(3), list(facevalue.keys()), rotation = 45); plt.colorbar(shrink = .1); plt.show()
